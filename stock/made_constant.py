import FinanceDataReader as fdrimport pandas as pdfrom eunjeon import Mecabimport requestsfrom bs4 import BeautifulSoupimport pandas as pdfrom time import sleepfrom datetime import datetime, timedeltadicList = pd.read_csv("../crawling/dictionary.csv", usecols=[1,2], encoding="CP949")dic = {}for d in dicList.values:    dic[d[0]] = d[1]thema = ["게임","겨울"]for t in thema:    for_code = pd.read_csv(f"../crawling/{t}.csv", usecols=[1], encoding="CP949")    for i in for_code.values:        if i[0] == "":            break        code = str(i[0])        code = "0" * (6-len(code)) + code        # df = fdr.DataReader(code,"2020-11-01","2020-11-30")        # df = df.rename_axis("Date").reset_index().sort_values(by=["Date"], ascending=False)        flag = False        page = 1        find_emo = {}        while True:            request = requests.get(f"http://www.paxnet.co.kr/news/{code}/stock?currentPageNo={page}")            soup = BeautifulSoup(request.text, "lxml")            ul = soup.find("div", {"id": "contents"}).find("div", {"class": "board-thumbnail"}).find("ul", {                "class": "thumb-list"})            li = ul.find_all("li")            for i in li:                date = i.find("dl").find("dd", {"class": "date"}).find_all("span")[1].text.split(" ")                if date[0] >= "2020.06.24":                    news = i.find("dl").find("dd", {"class": "date"}).find_all("span")[0].text                    if news != "인포스탁" and  (date[1] < "09:00" or date[1] > "15:30") :                        link = "http://www.paxnet.co.kr" + i.find("dl").find("dt").find("a")["href"]                        subRequest = requests.get(link)                        subSoup = BeautifulSoup(subRequest.text, "lxml")                        div = subSoup.find("div", {"id": "contents"}).find("div", {"class": "cont-area"}).find("div", {                            "class": "report-view"}).find("div", {"class": "report-view-cont"})                        p = div.find_all("p")                        content = div.find("div",{"id":"span_article_content"})                        textSum = []                        for cont in p:                            textSum.append(cont.text)                        textTemp = "".join(textSum)                        textTemp = "".join(content.text)                        dateT = datetime.strptime(date[0], "%Y.%m.%d")                        if date[1] > "15:30":                            dateT += timedelta(days=1)                            tempDateT = str(dateT).split(" ")                            find_emo[tempDateT[0]] = find_emo.get(tempDateT[0],"") + textTemp                        elif date[1] < "09:00":                            find_emo[date[0]] = find_emo.get(date[0],"") + textTemp                else:                    flag = True                    break            page += 1            if flag:                break        df = pd.DataFrame(index=range(0, ), columns=["thema","date", "score"])        count = 0        for k, v in find_emo.items():            cnt, score = 0,0            m = Mecab()            list = m.morphs(v)            for word in list:                if word in dic.keys():                    if dic[word] == 1:                        score += 1                    cnt += 1            if cnt != 0:                df.loc[count] = (code, k, int((score/cnt)*100))                count += 1        df.to_csv(f"./emoScore/{t}/{code}.csv", encoding="UTF-8")